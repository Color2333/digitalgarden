---
{"tags":["复习计划","期中考试","数据科学"],"dg-publish":true,"permalink":"/2025///","dgPassFrontmatter":true}
---


## PPT - 1
1. 数据科学的定义和应用场景
 看看 ppt 懂一下就行
 2. 掌握NumPy的ndarray数据结构及基本属性
## PPT-2
### 1 . 读取数据和保存数据的方法
{ #a01e1c}


读 csv 可以用函数 `np.loadtxt('xx.csv')`，函数全部的参数为 `fname`, `dtype`, `delimiter`, `skiprows` 分别为文件名，转化后数组的数据类型，分隔符的字符（默认为 none，自动选择），跳过的行数

``` python
import numpy as np
data=np.loadtxt('股票.csv',dtype='float',delimiter=',',skiprows=1)
```
还可以用 `genfromtxt`，对于空白行、缺省值的处理会更好，遇到注释行自动跳过（ # 开头 ）具体参数看
> 利用 genfromtxt 读取数据
[[2025/数据科学基础/课件/第2讲—第二章 数据组织与科学计算20250223.pdf#page=6&selection=15,0,19,4|第2讲—第二章 数据组织与科学计算20250223, 页面 6]]

用 `np.savetxt` 保存数据到文件中：

``` python
savetxt(fname, X, fmt='%.18e', delimiter=' ', newline='\n', header='', footer='', comments='#', encoding=None)
```
`fmt` ：格式字符串，指定数值的格式，如 “%. 2 f”（保留两位小数），默认是 "%. 18 e"（科学计数法）
### 2 . 获取数据后查看数据
`ndim` 查看维度，`dtype` 查看数据的类型，`type` 看的是整个对象的类型
`shape` 查看数组形状，二维的返回行数和列数（row，col），shape 也可以调整数组的大小, 实则是行列访问的变换
![image.png](https://jhspic.oss-cn-hangzhou.aliyuncs.com/undefined202504220026229.png)
比如：

``` python
a = np.array([[1,2,3],[4,5,6]])
 print (a.shape) //(2,3)
 a.shape = (3,2) 
 print (a)
```

![image.png](https://jhspic.oss-cn-hangzhou.aliyuncs.com/undefined202504220030781.png)
####  获取部分列的数据
访问第 row 行，第 col 列：`arr[row,col]`
访问数组 (row 1 ,col 1)、(row 2, col 2)、……等元素的：`arr[[row1,row2,row3],[col1,col2,col3]]`
回顾一下 python 的切片方式：Python中切片是左闭右开区间，即包含起始索引但不包含结束索引
NumPy切片的一般语法是：`array[start:stop:step, start:stop:step]`，这里：

- 对于每个维度，可以指定start（起始索引）、stop（结束索引，不包含）和step（步长）
- 如果省略start，则默认从0开始
- 如果省略stop，则默认到数组尾部
- 如果省略step，则默认为1

还有一些高级的切片技巧：

- 负索引表示从尾部计算，如-1表示最后一个元素
- 可以使用省略号`...`来表示在其位置选择所有可能的项
- 可以使用布尔数组进行条件筛选
以下面为例 ：

``` python
data1=data[:,-1] # `:` 表示选取所有行 `-1` 表示选取最后一列（在NumPy中，-1指的是数组的最后一个元素或最后一个维度）
data1=data[:,:2] # 第一个 `:` 表示选取所有行 `:2` 表示选取索引0到1的列（注意Python中切片是左闭右开区间，即包含起始索引但不包含结束索引）
```
{ #04070e}


### 3. 数据归一化
#### (1) MAX-MIN 最值法
公式原理如下。转换成[0-1]之间的数字
$$X^{'}=\frac{X-min}{max-min} $$
代码实现如下 ：

``` python
def MinMaxData(data):
	min=np.amin(data)
	max=np.amax(data)
	MinMax=(data-min)/(max-min)# 这一相当于每一个data中的对象都进行了这样的计算
	return MinMax
```
#### （2）Z-score 方法
公式原理如下。转换成[-1,1]之间的数，且均值为 0，标准差为 1 转换成标准正态分布
$$
X^{'}=\frac{X-\mu}{\delta}
$$
公式中，$\mu$ 为均值，$\delta$ 为标准差。均值为 `np.mean`，标准差为 `np.std`
代码实现如下：

``` python
def z_score_normalize(data):
 """ 对数据进行Z-score标准化 参数: data - 需要标准化的数据数组 返回: 标准化后的数据数组 """ 
 # 计算均值 
 mean = np.mean(data) 
 # 计算标准差 
 std = np.std(data) 
 # 应用Z-score公式:X' = (X - μ) / σ 
 normalized_data = (data - mean) / std 
 return normalized_data
```
### 4. 数据分析
#### 最大值和最小值
`amin` 是函数，`min` 是针对数组的方法。其中 `axis=0` 计算列最小值，`axis=1` 计算行最小值 
具体参数看
> numpy.Amax (a, axis=None, out=None, keepdims=False)
[[2025/数据科学基础/课件/第2讲—第二章 数据组织与科学计算20250223.pdf#page=12&selection=13,0,15,40|第2讲—第二章 数据组织与科学计算20250223, 页面 12]]
``` python
# 这两行代码功能完全相同
minStock = np.amin(data[:,3])  # 使用np.amin()函数
minStock = data[:,3].min()     # 使用.min()方法
```
#### 均值
`np.average` 参数具体可见下面。还有加权平均，weights 即为加权数组
> Numpy.Average (a, axis=None, weights=None, returned=False)
[[2025/数据科学基础/课件/第2讲—第二章 数据组织与科学计算20250223.pdf#page=13&selection=9,0,9,57|第2讲—第二章 数据组织与科学计算20250223, 页面 13]]
> 加权平均
[[2025/数据科学基础/课件/第2讲—第二章 数据组织与科学计算20250223.pdf#page=15&selection=7,0,7,4|第2讲—第二章 数据组织与科学计算20250223, 页面 15]]
#### 标准差、方差
`np.var` 方差，`np.std` 标准差
`ddof` 默认为 0，除数为 n，若为 1，除数为 n-1
``` python
# var()用来计算给定数组（或一维数组的某轴向）的样本方差或总体方差（由参数决定） 
Numpy.var(a,axis=None,dtype=None,out=None,ddof=0,keepdims=False) 
# std()计算样本标准差或总体标准差 
Numpy.std(a,axis=None,dtype=None,out=None,ddof=0,keepdims=False)
```
#### 数据分析
第一个方法直接返回符合条件的元素的值、第二个方法则返回符合条件的元素的位置

``` python
Arr[条件语句] 
numpy.Where (条件语句)
```


### 认识 ndarray
![image.png](https://jhspic.oss-cn-hangzhou.aliyuncs.com/undefined202504220139648.png)
### 数组初始化与重组
从文件初始化和保存到文件可见 1. 读取数据和保存数据的内容 [[#^a01e1c]]
#### 用array 方法转换列表等为 Numpy 数组
``` python
X=numpy.array(object，dtype，shape)
```
Object ：要转化为 Numpy 数组的数据对象，可以是列表、元组或者数组 
dtype：转化后数组的数据类型，若不设置则与原数据对象的数据类型保持一致 
shape：指定数组的形状，若不设置则与原数据对象的 shape 相同 
X：经转换后得到的数组
![image.png](https://jhspic.oss-cn-hangzhou.aliyuncs.com/undefined202504221017949.png)
#### `ones` 生成元素为 1 的数组
``` python
np.ones(shape,dtype=float)
```
如，`np.ones(6)` ，`np.ones((2,3),dtype=int)`
array([1., 1., 1., 1., 1., 1.])，array ([[1, 1, 1],[1, 1, 1\|1, 1, 1],[1, 1, 1]])
#### `zeros` 生成元素为 0 的数组，同上
#### `eye` 生成单位数组（单位矩阵）
```python
np.eye(5,dtype=int)
np.eye(5,7,dtype=int)
np.eye(5,7,k=1,dtype=int)
```
![image.png](https://jhspic.oss-cn-hangzhou.aliyuncs.com/undefined202504221025586.png)

K：对角线的偏移量。默认为 0 表示主对角线。正数表示高对角，负数表示低对角
#### 生成随机数数组

``` python
# 生成 [0-1) 区间内指定尺寸的均匀分布的随机数组，参数可以是数、元组或列表 
np.random.random(size) 
# 生成 [0-1) 区间内指定尺寸的均匀分布的随机数组
np.random.rand(d0,d1,...,dn)
# 生成指定范围[low~high)内的均匀分布的数组
np.random.uniform(low,high,size) 
# 生成指定范围[low~high)内的随机整数数组
np.random.randint(low,high,size,dtype)   
# 生成标准正态分布(均值为0，标准值为1)的随机数组
np.random.standard_normal(size)
# 生成标准正态分布 (loc为均值，scale为标准差，size为形状)
np.random.normal(loc,scale,size)
# 生成标准正态分布(均值为0，标准差为1)的随机数组
np.random.randn(d0,d1,...,dn)
```
#### 生成固定范围的数组 `arange`，`linspace`
``` python
np.arrange(start,stop,step) # 左闭右开，[start,stop）,step为步长
np.linspace(start,stop,num)# num为需要的数据量，都是闭区间

```
具体使用参数详见
> 生成固定范围的数组：arange，linspace
[[2025/数据科学基础/课件/第2讲—第二章 数据组织与科学计算20250223.pdf#page=31&selection=36,1,39,8|第2讲—第二章 数据组织与科学计算20250223, 页面 31]]
#### 索引及切片
![image.png](https://jhspic.oss-cn-hangzhou.aliyuncs.com/undefined202504221048070.png)
切片中的范围是左闭右开，即包括起始位置，不包括结束位置。
##### 布尔索引和条件索引
![image.png](https://jhspic.oss-cn-hangzhou.aliyuncs.com/undefined202504221053020.png)
例子：
``` python
row=['美的','格力','海尔','西门子'] 
data=np.array([[3800,1,15],[4000,8,20],[5000,2,30],[4000,20,50]]) 
bool_list=[False,False,True,False] 
print('布尔索引',data[bool_list]) 
con=data[:,0]<4500 # 条件语令
print('价格小于4500的商品',data[con]) 
print('价格小于4500的商品',data[data[:,0]<4500]) 
print('价格小于4000的商品对应的寿命',data[con,2])
```
#### 插入新行新列
``` python
np.insert(被插入数组，位置。插入内容，axis=0/1) # axis=1插入列 axis=0插入行，无axis 将展开输入数组（被插入的数组）
```
![image.png](https://jhspic.oss-cn-hangzhou.aliyuncs.com/undefined202504221106533.png)
> 插入新行（列）
[[2025/数据科学基础/课件/第2讲—第二章 数据组织与科学计算20250223.pdf#page=44&selection=10,0,10,7|第2讲—第二章 数据组织与科学计算20250223, 页面 44]]

#### 行列交换
``` python
#赋值 
a[:,2] = a[:,1] 
#第0行与第1行交换 
a[[0,1],:] = a[[1,0],:] 
#第0列与第2列交换 
a[:,[0,2]] = a[:,[2,0]] 
#本质是赋值 
a[:,[0,2]] = a[:,[3,1]]
```
#### 矩阵合并
**水平合并** ：列合并 `np.c_[]`
**垂直合并**：行合并 `np.r_[]`
![image.png](https://jhspic.oss-cn-hangzhou.aliyuncs.com/undefined202504221112956.png)
#### 矩阵运算
矩阵可以用算术符号进行计算，其中计算逻辑是对应位置的元素进行运算
![image.png](https://jhspic.oss-cn-hangzhou.aliyuncs.com/undefined202504221115023.png)
以下为 numpy 提供的运算符号，重点关注 `abs`，`sqrt`
``` python
print('两次考试的成绩和：',np.add(Score1,Score2)) 
Score_sub=np.subtract(Score1,Score2)
print('成绩差距以正数显示：',np.abs(Score_sub)) 
print('对成绩浮动进行开方：',np.sqrt(np.abs(Score_sub))) 
print('求浮动值的3次幂',np.power(np.abs(Score_sub),3)) 
print('成绩商：',np.divide(Score1,Score2)) 
print('百分制转换成十分制',np.divide(Score1,10)) 
print('成绩的积：',np.multiply(Score1,Score2)) 
print('第一次成绩对2取余：',np.mod(Score1,2)) 
print('两次考试的加权和',np.add(np.multiply(Score1,0.6),np.multiply(Score2,0.4)))
```
数组和标量的计算：通过广播的形式，扩充成形状相同的两个数组，进而将对应位置的数据进行运算
![image.png](https://jhspic.oss-cn-hangzhou.aliyuncs.com/undefined202504221117811.png)

数组点乘：一维为向量点乘，二维为矩阵的乘积
`np.dot()`
矩阵转置：`a.T`, `a.transpose()`
矩阵求逆：`numpy.linalg.inv(a)`
统计函数：axis=1 为行，axis=0 为列
![image.png](https://jhspic.oss-cn-hangzhou.aliyuncs.com/undefined202504221127406.png)
![image.png](https://jhspic.oss-cn-hangzhou.aliyuncs.com/undefined202504221131562.png)
### 线性回归建模
一元线性回归：
$$y=a_o+a_1x$$
多元线性回归：
$$
	y=a_0+a_1x_1+a_2x_2
$$
求法公式：
![image.png](https://jhspic.oss-cn-hangzhou.aliyuncs.com/undefined202504230003077.png)

Excel 中数据分析的线性回归也可以完成

## PPT-3
### 例题
> 【例3-1】某超市某一天饮料和牛奶的销售数据如下，要求找出销售额大于200元的商品，并分别统计饮料和牛奶的销售额。

[[2025/数据科学基础/课件/第三章 数据统计分析_20250323.pdf#page=3&selection=6,0,11,20|第三章 数据统计分析_20250323, 页面 3]]
> 例 3.1 DataFrame 数据访问

[[2025/数据科学基础/课件/第三章 数据统计分析_20250323.pdf#page=33&selection=2,0,6,4|第三章 数据统计分析_20250323, 页面 33]]
> 举例：根据数据字典： books={"书名": ['python程序设计', '数据科学','机器学习','人工智能'], " 单价": [25.0,28.99,23.0,32.0], "出版社": ['高等教育', '高等教育', '电子工业', '清华大学'], "数量": [45, 39, 44, 45]}

[[2025/数据科学基础/课件/第三章 数据统计分析_20250323.pdf#page=69&selection=0,3,29,20|第三章 数据统计分析_20250323, 页面 69]]
> 快餐数据集的查询与过滤

[[2025/数据科学基础/课件/第三章 数据统计分析_20250323.pdf#page=72&selection=15,0,15,11|第三章 数据统计分析_20250323, 页面 72]]
> 引例病人心率数据集

[[2025/数据科学基础/课件/第三章 数据统计分析_20250323.pdf#page=105&selection=23,0,25,7|第三章 数据统计分析_20250323, 页面 105]]
### Pandas 数据结构
#### Series 其实就是带标签的一维数组
Series 由两个数组组成，一个是 value（值），index（索引）。
同一个 series 只能存储一种类型的数据
![image.png](https://jhspic.oss-cn-hangzhou.aliyuncs.com/undefined202504230016499.png)
创建 series 对象：
``` python
# 直接创建
marks=pd.series(['a','b'],index=['1','2'])
# 字典创建
marks=pd.series({'1':'a','2':'b'})
# 用numpy数组创建
data=np.array(['a','b'])
index=np.array(['1','2'])
marks=pd.series(data,index)
```
##### Series 的对象属性：
`marks.index`: 索引
`marks.values`：值数组
`marks.dtype`：数据类型
`marks.name`：对象的语义描述
##### Series 对象访问：
访问单个值： ``Series[元素位置] 或 Series[' index ']``：例如 marks[1], marks['2252137']
访问多个值：``Series[[元素位置1,元素位置2,...\|元素位置1,元素位置2,...]] 或 Series[[‘index1’,’index2’\|‘index1’,’index2’]]`` ：例如 `marks[[1,3]]`, `marks[['2450011', '2450017']]`， `marks[1:3]` (切片用法，实则是 1 和 2 的元素)
条件查询：
`Series[条件语句]` 例如：`marks[marks=='良']`
#### DataFrame 二维表格
具有行、列两个轴向的索引
每个 DataFrame 对象由三部分组成： 行索引 index、列标签 columns 和值 values
##### 创建 DataFrame 对象
``` python
# 用列表创建
data=[['张海','交通工程','男',90],['段霞','金融学', '女',88], ['敬卫华','土木工程', '男',91],['李明','交通工程', '男',54], ['王丹','金融学', '女',67]] index = ['2450001', '2450002', '2450003', '2450004', '2450005'] 
column = ['姓名','专业','性别','成绩'] 
students = DataFrame(data,index=index,columns=column)
```

``` python
#用字典生成，这样就不用columns，只需要data和index
stu_dic2=pd.DataFrame({'姓名':['张海','段霞','敬卫华','李明','王丹'], '专业':['交通工程','金融学','土木工程','交通工程','金融学'], '性别':['男','女','男','男','女'], '成绩':[90,88,91,54,67]}, index = ['2450001', '2450002', '2450003', '2450004', '2450005']) 
# 第二种用字典生成的方法
lst=[{'姓名':'张海','专业':'交通工程','性别':'男','成绩':90}, {'姓名':'段霞','专业':'金融学','性别':'女','成绩':88}, {'姓名':'敬卫华','专业':'土木工程','性别':'男','成绩':91}, {'姓名':'李明','专业':'交通工程','性别':'男','成绩':54}, {'姓名':'王丹','专业':'金融学','性别':'女','成绩':67}] 
index = ['1850001','1850002','1850003','1850004','1850005’] # 根据key自动生成
columns students = DataFrame(data=lst,index=index)
```
``` python
# 利用numpy的array实现
import numpy as np 
import pandas as pd 
ndarray_data = np.array([['张海','交通工程','男',90],['段霞','金融学', '女',88],['敬卫华','土木工程', '男',91],['李明','交通工程', '男',54], ['王丹','金融学', '女',67]]) index = ['2450001', '2450002', '2450003', '2450004', '2450005'] column=['姓名','专业','性别','成绩’] 
df = pd.DataFrame(ndarray_data,columns=column) 
```

##### 查看 DataFrame 对象内容属性
看某一列，就用这一列的 `dtype` 查看如：`students['成绩'].dtype`
查看所有列的数据类型用 `types`
`index`、`columns`、`values` 获取索引、值
`shape` 获取形状

##### Dataframe 对象访问
看这个链接
> 2. DataFrame 数据选择

[[2025/数据科学基础/课件/第三章 数据统计分析_20250323.pdf#page=25&selection=0,0,4,4|第三章 数据统计分析_20250323, 页面 25]]
![image.png](https://jhspic.oss-cn-hangzhou.aliyuncs.com/undefined202504230106610.png)
**选取列**：`DataFrame['列名']` 或者 `DataFrame[['列名1'，'列名2'，]]`
**选取行**：`DataFrame.loc['行标签','列标签']`, `DataFrame.iloc['行序号','列序号']`
**选取单个值**：`DataFrame[column][index]` 先列后行，或者用上面那个方式，也是唯一的
**条件查询**：`df.loc[条件表达式，列名列表]` 如下：
``` python
#查询成绩大于等于90分的学生的姓名、成绩 
students.loc[students['成绩']>=90,['姓名','成绩']]
```
**数据修改**：对于 Series 对象和 DataFrame 对象，在选取了数据之后，就可以对选择的数据进行修改。
``` python
#将DataFrame对象students中第2个学生的成绩修改为85分 
students.iloc[1,-1]=85 
#将DataFrame对象students中“交通工程”专业修改为“交通类” 
students.loc[students.专业=='交通工程','专业']='交通类
```
**数据删除**：利用 `drop（）` 方法，要删除一个或多个数据，只需用一个索引数组或列表即可。drop 方法不删除原始对象的数据，而是根据删除后的数据生成新对象若要用新对象替换原对象，使用 drop 方法时，设置参数 inplace=True
``` python
#删除Series对象marks中学号为“24500013”,“2450015”的学生成绩 
marks.drop(['2450013','2450015'],inplace=True)
#删除DataFrame对象students中学号为“2450003”和“2450005”的学生行记录 
students.drop(['2450003','2450005'],inplace=True)
#删除DataFrame对象students中的“性别”列： 
students.drop('性别',axis=1,inplace=True)
```
DataFrame 对象的 drop 方法，用参数 axis 指明按行或列删除数据。Axis=0，删除数据的行，axis=1，删除数据的列。默认 axis=0
**添加数据**：
Series 对象可以直接添加数据、 DataFrame 对象可以添加新列
``` python
# 在marks中添加学号为“2450010”的学生 
marks['2450010']="及格" 
# 给students添加“年龄”列 
students['年龄']=[17,18,17]
```
#### 算数运算与数据对齐
##### 加法运算
``` python
mark1=Series([90,88,78,95,80], index=['2450011', '2450015', '2450013', '2450017', '2450012']) mark2=Series([5,7,8], index=['2450010','2450011','2450015']) 
mark1+mark2
```
Series 对象相加时，会自动进行数据对齐操作。 • 在重叠的索引处，对应值相加； • 在不重叠的索引处，使用 NaN 进行填充。 • NaN（Not a number）：代表缺失或者无效值，特殊的 float 类型
![image.png](https://jhspic.oss-cn-hangzhou.aliyuncs.com/undefined202504230129674.png)
两个 DataFrame 之间进行运算时
• 先进行形状的扩充 • 然后对应位置上的元素进行运算 • 注意：任何数与 NaN 进行运算都是 NaN
![image.png](https://jhspic.oss-cn-hangzhou.aliyuncs.com/undefined202504230130890.png)
用对象的 add、sub、mul、div 方法，进行算术运算
使用这些方法的 fill_value 参数，在算术运算时指定用于填充的值。
例如：mark 3.Add (bouns, fill_value=0)
![image.png](https://jhspic.oss-cn-hangzhou.aliyuncs.com/undefined202504230131827.png)
##### 与标量的运算 +、-、*、/ 

对象的每个元素均与标量运算
![image.png](https://jhspic.oss-cn-hangzhou.aliyuncs.com/undefined202504230132009.png)
##### DataFrame 与 series 运算
以广播的形式：具体细节如下：用对象的算术运算方法时，通过 axis 参数指定广播方向。若 axis=0 (或'index' )，按照行索引对齐，在列上广播；若 axis=1 (或'columns')，按照列名称对齐，在行上广播。Axis 默认为 1。
![image.png](https://jhspic.oss-cn-hangzhou.aliyuncs.com/undefined202504230138108.png)
#### 重建与更换索引
`df.reindex(index=[])` 利用 reindex 重新指定索引，会创造一个新对象，如果要代替原来的，采用 `inplace=Ture`
![image.png](https://jhspic.oss-cn-hangzhou.aliyuncs.com/undefined202504231356429.png)

`df.rename()` 可以重新指定索引（index）和列名（columns），同样会创造一个新对象。
``` python
students.rename(columns={'姓名':'学生姓名','成绩':'学生成绩'})
```
![image.png](https://jhspic.oss-cn-hangzhou.aliyuncs.com/undefined202504231356666.png)

`df.set_index(列名)` 可以用新的列作为索引，同样会创造一个新的对象
![image.png](https://jhspic.oss-cn-hangzhou.aliyuncs.com/undefined202504231355050.png)

`df.reset_index(drop=False)` 还原为整形索引，之前的索引如果 drop=False 不删除，反之删除。
![image.png](https://jhspic.oss-cn-hangzhou.aliyuncs.com/undefined202504231355704.png)
#### 其他常用操作
唯一值：
`df。unique（）` Series 对象，或者 DataFrame 中某列的唯一值数组，输出的是值
`df。nunique()` 统计某列不同值的个数，输出的是数量
值计数：
`df.value_count()` 计算 dataframe 中某列中每个值出现的频率
``` python
value_counts(sort=True,ascending=False,normalize=False,bins=None,dropna=True)
```
成员资格：
`df。isin` 来判断 DataFrame 对象列的成员资格，返回一个布尔值的 Series 对象
![image.png](https://jhspic.oss-cn-hangzhou.aliyuncs.com/undefined202504231403970.png)
### 数据加载与保存
#### 加载 CSV/TXT 文件
`pd.read_csv` 读取以“，”为分隔符的 csv 文件，返回 DataFrame 对象
`pd。read_table` 读取以"/t"为分隔符的文本文件，返回 DataFrame 对象
具体参数详见
> 1. 加载 CSV/TXT 格式文件

[[2025/数据科学基础/课件/第三章 数据统计分析_20250323.pdf#page=56&selection=117,0,121,4|第三章 数据统计分析_20250323, 页面 56]]
`header` 设置表头为第几行，也可以用 `names` 参数为每列指定列名
`index_col` 指定某一列为索引，`usecols` 读取指定的几列
`encoding` 是编码，一般是 `gbk`，`utf-8`，`ANSI` 等
查看导入的数据
``` python
data.head() #查看前5行 
data.head(2) #查看前2行 
data.tail() #查看最后几行数据，默认为后5行
print(data.describe()) #查看整体数值列的各项统计数据
```
![image.png](https://jhspic.oss-cn-hangzhou.aliyuncs.com/undefined202504231412437.png)
> [!INFO]
> 大数据集的处理
> 1) 加载数据集到相同大小的区块中（静态分块，块大小由chunksize固定设置） • pd.read_csv() 提供chunksize参数，用于指定每次读取多少行数据 • 对返回的可迭代对象进行遍历，可一次处理一小块数据
> 2) 动态决定每个区块的大小 • 动态决定时，首先需要将read_csv函数的参数iterator设置为True，返回一个迭代器（而不是DataFrame） • 使用get_chunk(n)方法，手动获取下一块数据，其中n设置为想要读取的行数

``` python
#读取文件的前5行并显示 
data_iterator=pd.read_csv(r'pop.csv', header=3,skiprows=[4], iterator=True,encoding="gbk") 
piece=data_iterator.get_chunk(5) 
```
保存数据：
`df.to_csv()` 将 dataframe 对象存储到 CSV 文件，参数可见
> 将 DataFrame 对象保存到 CSV 文件

[[2025/数据科学基础/课件/第三章 数据统计分析_20250323.pdf#page=67&selection=6,0,11,2|第三章 数据统计分析_20250323, 页面 67]]
读取 Excel 数据：
`pd.read_excel()` 从 excel 中读取文件数据转成 DataFrame 对象
``` python
data2=pd.read_excel(r"pop.xlsx", sheet_name='Sheet1',header=3,skiprows=[4]) data2.head()
```
### 数据预处理
#### 数据合并
Pandas 提供了三种不同的数据合并方式： 
① `pd.merge () ` 函数——类似 SQL 的 join 以数据库连接方式合并数据，可根据一个或多个键，将不同 DataFrame 对象的行进行匹配合并 
② `pd.concat () ` 函数——按行或列拼接将多个 DataFrame 沿着行或列进行连接，类似于沿着一条轴，将多张表上下堆叠或左右拼接
③ `df. combine_first () ` 方法——补充缺失值将两个 DataFrame 合并，以第一个 DataFrame 为主，如果第一个 DataFrame 中某些位置是缺失值（NaN），就用第二个 DataFrame 对应位置的值进行填充
##### 数据库方式合并
``` python
pd.merge(left,right,how='inner',on=None,… )
```
![image.png](https://jhspic.oss-cn-hangzhou.aliyuncs.com/undefined202504231434457.png)
![image.png](https://jhspic.oss-cn-hangzhou.aliyuncs.com/undefined202504231435824.png)
##### 轴向堆叠数据
``` python
colnames=['学号','姓名','性别','专业','成绩'] data1=[['2450001','张海','男','交通工程',90], ['2450002','段霞','女','金融学',88], ['2450003','敬卫华','男','土木工程',91]] 
data2= [['2450004','李明','男','交通工程',54], ['2450005','王丹','女','金融学',67]] 
group1=DataFrame(data1,columns=colnames) 
group2=DataFrame(data2,columns=colnames) 
scores=pd.concat([group1,group2]) # 默认axis=0
print(scores)
```
![image.png](https://jhspic.oss-cn-hangzhou.aliyuncs.com/undefined202504231436000.png)
同理，轴向列堆叠（axis=1）：
![image.png](https://jhspic.oss-cn-hangzhou.aliyuncs.com/undefined202504231437069.png)
##### 合并重叠数据
``` python
data1={'姓名':[np.nan, np.nan,'李明'], '性别':['男',np.nan,'男']} 
index1=['2450001','2450002','2450004'] 
stu1 = DataFrame(data1,index=index1) data2={'姓名':['张海','段霞','敬卫华'], '性别':[np.nan,'女','男'], '成绩':[90,88,91]} 
index2=['2450001','2450002','2450003'] 
stu2 = DataFrame(data2,index=index2) 
result_data = stu1.combine_first(stu2) 
```
![image.png](https://jhspic.oss-cn-hangzhou.aliyuncs.com/undefined202504231439079.png)

#### 数据清洗
##### 处理缺失数据
Pandas 常用 `NaN` 代表浮点或非浮点数据中的缺失值，Python 内置的 None 也会被当做缺失值来处理。
用 DataFrame/Series 对象的 `isnull () ` 方法，返回形状相同的布尔型 DataFrame/Series 对象，查看缺失值是否存在，True 表示是缺失值。
• `<对象名>. isnull (). any ()` 查看每列是否含有缺失值 
• `<对象名>. isnull (). any (axis = 1) ` 查看每行是否含有缺失值 
• `<对象名>. isnull (). all () ` 查看每列是否全为缺失值 
• `<对象名>. isnull (). all (axis=1)` 查看每行是否全为缺失值，即 `all (1)`

处理缺失值方法：1）滤除缺失值 2) 填充缺失值
**滤除缺失值**：`df.dropna(axis=0, how='any', thresh=None, inplace=False)`
**填充缺失值**：`df.fillna(value=None,method=None,axis=None,inplace=False)`
##### 去除重复数据
``` python
#检测那些行是重复行 
is_dup = df.duplicated() 
#删除重复行 
result = df.drop_duplicates()
```

##### 内容和格式的清洗
> `df.replace (to_replace, value, inplace, method)`

[[2025/数据科学基础/课件/第三章 数据统计分析_20250323.pdf#page=103&selection=31,0,31,43|第三章 数据统计分析_20250323, 页面 103]]
示例：将性别 male 替换为'男'，female 替换为'女' ，将年龄-1 替换成 30 岁
``` python
patient_data.replace({'male':'男','female':'女'},inplace=True) 
patient_data['年龄'].replace(-1,30,inplace=True)
```
> 将身高的单位统一成‘m

[[2025/数据科学基础/课件/第三章 数据统计分析_20250323.pdf#page=104&selection=73,1,75,0|第三章 数据统计分析_20250323, 页面 104]]

``` python
# 获取身高以cm为单位的行(布尔值)，遇到缺失值默认返回
False rows_with_cm = patient_data['身高'].str.contains('cm',na=False)
#仅仅对含有cm的每一行，去掉后缀cm，转换为m 
for i,row in patient_data[rows_with_cm].iterrows(): 
 #使用迭代器 
 height =float(row['身高'][:-2])/100 
 #身高的值转换为float,并换算为m的值 
 patient_data.loc[i,'身高'] = f'{height:.2f}' +'m' 
 # 该列值带上单位'm' # 去掉身高数据中的单位 
 patient_data['身高']=patient_data['身高'].str[:-1] 
 # 将该列重命名为"身高/m" 
 patient_data.rename(columns={'身高':'身高/m'},inplace=True)
```

#### 数据转换
##### 用函数变换
•Numpy的元素级数组方法可用于Pandas对象，如 `np.abs(df)`，`np.sqrt(df)`，`np.log(df) `
• DataFrame/Series对象的`apply(f)`方法将函数f应用到DataFrame对象的各列或行形成的一维数组上。axis为0时，作用到每一列上；axis为1时，作用到每一行上。axis默认为0。 
• DataFrame对象的`applymap(f)`方法将函数f应用到DataFrame对象的每个元素上。 
• Series对象的 `map(dict)` 方法对 Series 中的每个元素应用映射规则，可以是一个函数，也可以是一个字典或Series。如果传入的是函数，则对每个元素执行该函数的运算。如果传入的是字典或另一个Series，则根据“键-值”对进行替换。

示例：函数变换
``` python
from pandas import DataFrame 
marks=DataFrame({'高数':[90,85,85,90],'英语':[85,92,87,95], '程序设计':[90,80,82,97]}, index=['张楠','吴京','李海明','王华']) 
def f(x): 
	return x+2 
marks=marks.applymap(f) 

marks['程序设计']=marks['程序设计'].apply(lambda x:"优" if x>=90 else "良") print(marks)
```
示例：map 映射
``` python
iris_data=pd.read_csv('iris_6.csv') # 读取 6朵鸢尾花数据 
# 1.先构造映射字典，键是原本类别名称，值是对应的数字编码 
target_value={"Iris-setosa":1,"Iris-versicolor":2,"Iris-virginica":3} 
# 2. 然后，在target列上应用map函数： 
iris_data['target']=iris_data['target'].map(target_value)
```
![image.png](https://jhspic.oss-cn-hangzhou.aliyuncs.com/undefined202504231457635.png)

##### 离散化（针对连续性数据）
将原本连续的数值特征划分为若干个区间（面元），并用区间标签来代替原有数值。
``` python
students=pd.read_csv('students_info.csv',header=0,encoding='gbk') 
bins=[0,60,70,80,90,101] 
names=['不及格','及格','中','良','优'] 
students['等级']=pd.cut(students['成绩'],bins,labels=names,right=False) print(students)
```
主要实现的函数：
> `pd.cut (X, bins, right= True, labels=None, …)` 离散化
[[2025/数据科学基础/课件/第三章 数据统计分析_20250323.pdf#page=114&selection=68,0,70,3|第三章 数据统计分析_20250323, 页面 114]]

> `pd.qcut (x, q, labels=None, retbins=False)`

[[2025/数据科学基础/课件/第三章 数据统计分析_20250323.pdf#page=115&selection=18,0,19,1|第三章 数据统计分析_20250323, 页面 115]]
按照样本的分位数来分箱，自动计算分位点，把数据分割成若干区间，并保证每个区间样本数大致相同（等频划分）；或者按照自定义的分位数列表来分箱，不一定等频。
##### 哑变量矩阵编码分类特征（针对分类特征）
One-hot 编码为哑变量矩阵-适用于无序的分类特征：性别城市等
``` python
dummies=pd.get_dummies(data['ages'],prefix='age', dtype='uint8')
# 针对 ages 列里出现的每一种分类（如 '少年', '青年', '中年'），创建一 个形如 age_少年, age_青年, age_中年 的新列。
```
示例：鸢尾花数据
``` python
iris_data=pd.read_csv(r'iris_6.csv') 
dummies=pd.get_dummies(iris_data['target']) # 对target列进行one-hot编码 
data = iris_data.iloc[:,:-1] # 不含target列 
data_with_dummy=pd.concat([data,dummies],axis=1,dtype='uint8') # 合并 
data_with_dummy=data.join(dummies)# 合并方式2
```
#### 数据排序
DataFrame 对象既可以按照值排序，也可以按照索引排序
1）`df. sort_values (by,[参数列表]) ` 根据某列或多列的值进行排序 • by：指定排序的关键列或列列表，不可缺省，列名字符串或列名组成的列表。
`DataFrame.sort_values(by, axis=0, ascending=True, inplace=False, kind='quicksort', na_position='last', ignore_index=False,…)`
• ascending：指定排序方式，True 为升序，False 为降序。或为一个布尔列表与 by 列表对应。 • kind：指定排序算法，值可取“quicksort”、“mergesort”或“heapsort”。 • na_position：缺失值（NaN）排在开头 (‘first’) 还是末尾 (‘last’)。
2）`df. sort_index ([参数列表])` 根据行索引或列索引进行排序 • axis：axis=0 按行索引排序；axis=1 按列索引排序。
`DataFrame.sort_index(axis=0, ascending=True,inplace=False, kind='quicksort', na_position='last',...)`